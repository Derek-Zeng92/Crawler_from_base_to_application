s = "你好"
# 文字在存储的时候需要有个转换的标准
# 编码
# ascii  -> 美国标准信息交换代码
# 美国人用数字, 字母, 美国的标点符号还有一些特殊操作符
# ascii 由8位01组成, 用了128个位置 1个字节
# ANSI标准, ascii扩充了一倍长度  2个字节
# 16位 01  65536个位置
#  美国人在当年是没有能力编排出世界所有国家的文字的
# 把ascii保留, 把剩下的位置. 给到各个国家.
# ANSI(ascii, 中国)
# ->
# 在ascii的基础上把中国汉字怼进去了
# -> GB2312 GUO BIAO  几千个字儿
# -> GBK 国标码的扩展码 <- 这个用的最多 2byte
# -> 10010 -> 我
# -> GB18030 目前非常全面的中国自己的编码

# ANSI(ascii, 日本)
# KAWAYI
# -> 10010 -> 三

# 无法将GBK的东西(文件) 直接发给其他编码的计算机

# 在重新做一个标准(unicode), 2byte -> 65536个位置
# 不够用  4byte -> 20亿~40亿之间
# 一个新的问题. 资源浪费
# 这个全新的标准确实能存储全世界所有国家的文字符号
# 无法进行正常使用(空间浪费)
# 能不能进行压缩
# 对全新的编码进行使用的时候. 提出了一个全新的概念
# 可变长度-unicode
# 长度是不统一的。
# 英文字母 -> 8bit -> 1个字节 -> ascii
# 欧洲文字 -> 16bit -> 2个字节
# 中文  -> 24bit -> 3个字节

# 能存中文
# gbk里面的文字 -> 2byte -> 英文， 中文， 日文， 韩文, 繁体文字
# utf-8 -> 3byte ->  所有国家的文字符号

# 在python中, 程序运行起来之后. 你的字符串.
# 在内存中是 unicode
# 落实在硬盘上.对字符串进行编码操作(gbk, utf-8)

#

# encode()
bs = s.encode("utf-8")  # 3 x 2 => 6
# b'\xe4\xbd\xa0\xe5\xa5\xbd' # utf-8 -> 6
# b'\xc4\xe3\xba\xc3'  # gbk -> 4

# gbk和utf-8  能直接转换吗？？
print(bs)

# b''  -> 字节

# gbk只能用gbk来处理。 utf-8只能由utf-8处理

# bytes
bs = b'\xe4\xbd\xa0\xe5\xa5\xbd'  # gbk? utf-8?

# 字节变回字符串
s = bs.decode("utf-8")  # 如果报错或者这里展示的东西不对劲
print(s)

# 1. 记住。  2. 去看基础
# GBK utf-8
#
# encode
# decode

